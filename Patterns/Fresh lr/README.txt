Sample outputs and usage of 'perceptron' 
Files in this directory:
README: this file
lr.pat, lr_test.pat: pattern files for the left-right problem,
	identical with the ones in ../A4/patterns/left-right/
lr_start.wts: sample initial weight file generated by 'perceptron'
lr_end.wts: sample final weight file
lr.seed: seed file used to generate lr_start.wts
lr_test.out: sample 'test' output file

How the files were generated:
0) lr.seed, lr_start.wts
> perceptron -p lr.pat -S lr.seed -s lr_start.wts -n 0
	(When 'n' is set to 0, my program initializes the weights,
	but exits without training.)
*Your program may not give exactly the same weight file even if you
use the same seed, and that is fine. You may be able to figure out
the order my program initializes the biases and weights by comparing 
it with your output, however, matching them is NOT a requirement.
*Do make sure all the biases and weights are in the specified range
initially ([-0.1, 0.1) by default).

1) lr_end.wts
> perceptron -p lr.pat -l lr_start.wts -s lr_end.wts
epoch   1 :  patterns incorrect =  18
epoch   2 :  patterns incorrect =  11
epoch   3 :  patterns incorrect =   6
epoch   4 :  patterns incorrect =   6
epoch   5 :  patterns incorrect =   0
*By starting from the same initial weight file, all programs should give
exactly the same result

> perceptron -p lr.pat -S lr.seed -s lr_end.wts
*This will give the same result for my program, but maybe not for yours

1.1)
> perceptron -p lr.pat -l lr_end.wts
epoch   1 :  patterns incorrect =   0
*No training should take place if you start from 'lr_end.wts'

1.2)
> perceptron -p lr_test.pat -l lr_end.wts
epoch   1 :  patterns incorrect =   0
*Should perform correctly on all patterns in 'lr_test.pat' as well!

2) lr_test.out
> perceptron -p lr_test.pat -l lr_end.wts -t lr_test.out
*To verify that all patterns are correct, compare lr_test.out with the 
desired output patterns in 'lr_test.pat'.


*For those who can't sleep well unless everything completely matches*
This is the order I initialized the biases and the weights:
I first fix the output unit, initialize the bias, then the weights 
for that output unit starting from the 0th input up to the last.
Iterate this for all the output units. 
Why not initialize all the biases, then the weights, or vice versa?
Because it saves me one 'for' loop.

100) README
Done!